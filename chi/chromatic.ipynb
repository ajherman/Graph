{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some new ideas...\n",
    "\n",
    "Let's start with independent sets. An independent set is a binary vector $x$, such that $x^TAx=0$, where $A$ is the adjacency matrix. Finding the independence number means maximizing the weight of $x$. Can we phrase this as an optimization problem? Trying to minimize $x^TAx$ is not a problem, since $A$ is a psd matrix. However, without additional constraints, this would just lead to $x=0$, which is clearly not optimal. \n",
    "\n",
    "What if we fix the size of the independent set, $K$? Then we are looking for vectors that have a fixed norm (either L1 or L2). Let's further restrict all of our values to lie between 0 and 1. If we fix $|x|$, then forcing $x$ to be binary corresponds to minimizing $|x|_1$ (I think). \n",
    "\n",
    "Proof: Suppose $|x|=\\sqrt{K}$. Note that since $x\\in[0,1]^N$, we have $1-x\\ge 0$, and so $x\\cdot(1-x)\\ge 0$. Therfore, $|x|_1=x\\cdot 1\\ge x\\cdot x=|x|^2=K$. Further, equality holds exactly when $x$ is binary, in which case $|x|_1=K$. \n",
    "\n",
    "Therefore, if there is an independent set of size $K$, we should be able to find it be minimizing $x^TAx+|x|_1$ with the constraint $|x|=\\sqrt{K}$, $x\\in[0,1]^N$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "class energyModel(torch.nn.Module):\n",
    "    def __init__(self, A, lam=1.0):\n",
    "        super(energyModel, self).__init__()\n",
    "        self.A = A\n",
    "        self.lam = lam\n",
    "\n",
    "    def forward(self, x):\n",
    "        energy = x.t()@self.A@x+self.lam*torch.norm(x,1)\n",
    "        return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1:  25.566421508789062\n",
      "Independence:  74.85324096679688\n",
      "\n",
      "L1:  11.855396270751953\n",
      "Independence:  8.449209213256836\n",
      "\n",
      "L1:  6.857504844665527\n",
      "Independence:  0.08543948829174042\n",
      "\n",
      "L1:  5.118616580963135\n",
      "Independence:  0.0\n",
      "\n",
      "L1:  4.3925251960754395\n",
      "Independence:  0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# sys.path.insert(1, '../OldStuff')\n",
    "# from GraphFun import *\n",
    "\n",
    "K = torch.tensor(4.0) # Size of independent set\n",
    "\n",
    "# Petersen graph adjacency array\n",
    "A = np.array([\n",
    "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
    "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 1, 0, 1, 0, 1, 0],\n",
    "       [0, 0, 0, 0, 1, 1, 0, 1, 0, 0],\n",
    "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 1],\n",
    "       [0, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
    "       [0, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "       [1, 0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
    "       [1, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
    "       [1, 1, 0, 0, 1, 0, 0, 0, 0, 0]])\n",
    "\n",
    "# G = genJohnsonGraph(4,2,1)\n",
    "# A = getAdjArray(G)\n",
    "# print(A)\n",
    "\n",
    "# A=np.array([[0, 1, 1, 1, 1, 0], # Octahedron\n",
    "#        [1, 0, 1, 1, 0, 1],\n",
    "#        [1, 1, 0, 0, 1, 1],\n",
    "#        [1, 1, 0, 0, 1, 1],\n",
    "#        [1, 0, 1, 1, 0, 1],\n",
    "#        [0, 1, 1, 1, 1, 0]])\n",
    "\n",
    "# A = np.load(\"Jvki_graphs/J_10_4.npy\")\n",
    "# A = torch.tensor(A,dtype=torch.float32)\n",
    "# N = A.shape[0] # Number of vertices\n",
    "\n",
    "# Init x\n",
    "x = torch.randn(N,requires_grad=True)\n",
    "x.data = torch.abs(x.data)\n",
    "x.data = torch.clamp(x.data,0,1) # Project x to [0,1]\n",
    "x.data = x.data*torch.sqrt(K)/torch.norm(x.data,2) # Normalize x\n",
    "\n",
    "# Create model / optimizer\n",
    "model = energyModel(A)\n",
    "optimizer = torch.optim.Adam([x], lr=0.001)\n",
    "\n",
    "# Minimize energy of x\n",
    "for i in range(5000):\n",
    "    optimizer.zero_grad()\n",
    "    energy = model(x)\n",
    "    energy.backward()\n",
    "    optimizer.step()\n",
    "    x.data = torch.clamp(x.data,0,1) # Project x to [0,1]\n",
    "    x.data = x.data*torch.sqrt(K)/torch.norm(x.data,2) # Normalize x\n",
    "    x.data = torch.clamp(x.data,0,1)\n",
    "    if i%1000==0:\n",
    "        print(\"L1: \",torch.norm(x,1).item())\n",
    "        print(\"Independence: \",(x.t()@A@x).item())\n",
    "        # print(\"Energy: \",energy)\n",
    "        print(\"\")\n",
    "        # print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like this isn't really work. At least it's not working well. Even if we set $\\lambda=0$, it can still fail to find the optimum. I'm guessing this is being the L2 norm constraint makes the optimization non-convex. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another idea I want to explore is using symmetric polynomials to try to find colorings. Suppose we thinking of coloring Johnson graphs as a problem of mapping $k$-sets of integers (modulo v), to elements of $v$. The goal is to find a symmetric function in the variable $x_1,\\ldots, x_k$ such that 1) $f(\\bar{x})$ is injective in each coordinate, given fixed values of the other coordinates and 2) the range of $f$ is as small as possible.\n",
    "\n",
    "The first condition is necessary so that whenever to vertices differ in a single element, $f$ will assign them different values. Note further, that (I think) every symmetric function on $[v]$ is a symmetric polynomial...maybe. \n",
    "\n",
    "That's one approach. A more general approach would be to do some sort of annealing. Let's say we are trying to $K$-color our graph. We assign a $K$-vector to each vertex. Our goal is to end up with one-hot vectors that are orthogonal for adjacenct vertices. But to start, we will allow the vectors to take on a continuum of values. The neighbors of a vector will be used to flip it's value..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best:  0.0\n",
      "Mean:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Get graph\n",
    "v,k = 5,2\n",
    "A = np.load(\"Jvki_graphs/J_\"+str(v)+\"_\"+str(k)+\".npy\")\n",
    "A = torch.tensor(A,dtype=torch.float32)\n",
    "N = A.shape[0] # Number of vertices\n",
    "\n",
    "c = 5\n",
    "beta=0.02 # Temperature\n",
    "# x = torch.randn((N,c),requires_grad=True) # Logits\n",
    "\n",
    "# p = torch.softmax(0.1*x,dim=1) # probabilities\n",
    "# loss = torch.sum(A*(p@p.t())) # Covariance matrix\n",
    "\n",
    "# optimizer = torch.optim.Adam([x], lr=0.1)\n",
    "\n",
    "# Minimize loss\n",
    "# best_val = v\n",
    "vals = []\n",
    "for trial in range(50):\n",
    "    x = torch.randn((N,c),requires_grad=True) # Logits\n",
    "    optimizer = torch.optim.Adam([x], lr=5.0)\n",
    "    for i in range(2000):\n",
    "        optimizer.zero_grad()\n",
    "        p = torch.softmax(beta*x,dim=1) # probabilities\n",
    "        # loss = torch.sum(torch.tensor([p[:,i].t()@A@p[:,i] for i in range(c)])) # Entropy\n",
    "        loss = torch.sum(A*(p@p.t())) # Covariance matrix\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # print(\"Loss: \",loss.item())\n",
    "    # print(\"Independence: \",torch.sum(A*(p@p.t())).item())\n",
    "    # print(\"\")\n",
    "\n",
    "    coloring = torch.softmax(20*x,dim=1)\n",
    "    # print(p)\n",
    "    # print(p>0.5)\n",
    "    val = torch.sum(A*(coloring@coloring.t())).item()\n",
    "    vals.append(val)\n",
    "    if val<0.1:\n",
    "        break\n",
    "    # best_val = min(best_val,val)\n",
    "vals = np.array(vals)\n",
    "print(\"Best: \",np.min(vals))\n",
    "print(\"Mean: \",np.mean(vals<0.1))\n",
    "# print(\"Std: \",np.std(vals))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this version, our underlying variable, $x$, can be an arbitrary vector. And we take the probability to be its softmax. Then we trying to get adjecent vertices to have orthgonal probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17613/1209152927.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mani\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manimation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuncAnimation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mani\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.gif'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagemagick'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0;31m# callback a no-op; canvas.manager = None prevents resizing the GUI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0;31m# widget (both are likewise done in savefig()).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrc_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'savefig.bbox'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m              \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m              cbook._setattr_cm(self._fig.canvas,\n",
      "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36msaving\u001b[0;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36mfinish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0moverridden_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Inline _cleanup() once cleanup() is removed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrab_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msavefig_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36m_cleanup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Inline to finish() once cleanup() is removed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;34m\"\"\"Clean-up and collect the process used to write the movie file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0;31m# Use the encoding/errors that universal_newlines would use.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextIOWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2019\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   2020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Petersen graph\n",
    "A = np.array([\n",
    "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
    "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 1, 0, 1, 0, 1, 0],\n",
    "       [0, 0, 0, 0, 1, 1, 0, 1, 0, 0],\n",
    "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 1],\n",
    "       [0, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
    "       [0, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "       [1, 0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
    "       [1, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
    "       [1, 1, 0, 0, 1, 0, 0, 0, 0, 0]])\n",
    "A = torch.tensor(A,dtype=torch.float32) #-torch.eye(10)\n",
    "N = A.shape[0] # Number of vertices\n",
    "n_steps = 800\n",
    "c = 3\n",
    "beta=0.02 # Temperature\n",
    "\n",
    "# Minimize loss\n",
    "vals = []\n",
    "x = torch.randn((N,c),requires_grad=True) # Logits\n",
    "x.data = 10*x.data\n",
    "optimizer = torch.optim.Adam([x], lr=0.1)\n",
    "points =[]\n",
    "losses = []\n",
    "\n",
    "for step in range(n_steps):\n",
    "    optimizer.zero_grad()\n",
    "    p = torch.softmax(beta*x,dim=1) # probabilities\n",
    "    points.append(p.detach())\n",
    "    loss = torch.sum(A*(p@p.t())) # Covariance matrix\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# print(\"Loss: \",loss.item())\n",
    "# print(\"Independence: \",torch.sum(A*(p@p.t())).item())\n",
    "# print(\"\")\n",
    "\n",
    "coloring = torch.softmax(20*x,dim=1)\n",
    "# print(p)\n",
    "# print(p>0.5)\n",
    "val = torch.sum(A*(coloring@coloring.t())).item()\n",
    "print(val)\n",
    "points = torch.stack(points).numpy()\n",
    "R = np.array([[1/np.sqrt(3),1/np.sqrt(3),1/np.sqrt(3)],\n",
    "              [1/np.sqrt(2),-1/np.sqrt(2),0],\n",
    "              [1/np.sqrt(6),1/np.sqrt(6),-2/np.sqrt(6)]])\n",
    "\n",
    "in_plane = (points@R.T)[:,:,1:] #-np.array([1]+[0]*(c-1))/np.sqrt(c)\n",
    "\n",
    "# Animate points of in_plane as moving scatter plot\n",
    "fig, ax = plt.subplots()\n",
    "scat = ax.scatter(in_plane[0,:,0], in_plane[0,:,1],s=30)\n",
    "\n",
    "ax.set_xlim([-0.8,0.8])\n",
    "ax.set_ylim([-0.8,0.8])\n",
    "\n",
    "def update(frame_number):\n",
    "    scat.set_offsets(in_plane[frame_number])\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=n_steps, interval=50)\n",
    "ani.save('test.gif', writer='imagemagick', fps=30)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's another version. Rather than using softmax, we just normalize the vectors at each step while trying to push the angle between adjacent vertices towards 90. The probability will be defined by squaring all the entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.017468452453613\n"
     ]
    }
   ],
   "source": [
    "# Petersen graph\n",
    "A = np.array([\n",
    "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
    "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 1, 0, 1, 0, 1, 0],\n",
    "       [0, 0, 0, 0, 1, 1, 0, 1, 0, 0],\n",
    "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 1],\n",
    "       [0, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
    "       [0, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "       [1, 0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
    "       [1, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
    "       [1, 1, 0, 0, 1, 0, 0, 0, 0, 0]])\n",
    "A = torch.tensor(A,dtype=torch.float32) #-torch.eye(10)\n",
    "N = A.shape[0] # Number of vertices\n",
    "n_steps = 800\n",
    "c = 2\n",
    "beta=0.02 # Temperature\n",
    "\n",
    "# Minimize loss\n",
    "vals = []\n",
    "\n",
    "# Init x\n",
    "x = torch.randn((N,c),requires_grad=True) # Logits\n",
    "x.data = torch.nn.functional.normalize(x.data, p=2, dim=1)\n",
    "\n",
    "optimizer = torch.optim.Adam([x], lr=0.1)\n",
    "# optimizer = torch.optim.SGD([x], lr=0.005)\n",
    "points =[]\n",
    "losses = []\n",
    "\n",
    "for step in range(n_steps):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    y = x**2\n",
    "    # p = y/torch.sum(y,dim=1,keepdim=True) # probabilities\n",
    "    total = torch.sum(y,dim=1,keepdim=True)\n",
    "    # print(total)\n",
    "    p = y#/total\n",
    "    # p = torch.nn.functional.normalize(y, p=1, dim=1)\n",
    "\n",
    "    points.append(p.detach())\n",
    "    loss = torch.sum(A*(p@p.t())) # Covariance matrix\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    x.data = torch.nn.functional.normalize(x.data, p=2, dim=1)\n",
    "\n",
    "# print(\"Loss: \",loss.item())\n",
    "# print(\"Independence: \",torch.sum(A*(p@p.t())).item())\n",
    "# print(\"\")\n",
    "\n",
    "# coloring = x**2 #torch.softmax(20*x,dim=1)\n",
    "coloring = torch.softmax(10*p,dim=1)\n",
    "\n",
    "# print(p)\n",
    "# print(p>0.5)\n",
    "val = torch.sum(A*(coloring@coloring.t())).item()\n",
    "print(val)\n",
    "\n",
    "\n",
    "# points = torch.stack(points).numpy()\n",
    "# R = np.array([[1/np.sqrt(3),1/np.sqrt(3),1/np.sqrt(3)],\n",
    "#               [1/np.sqrt(2),-1/np.sqrt(2),0],\n",
    "#               [1/np.sqrt(6),1/np.sqrt(6),-2/np.sqrt(6)]])\n",
    "\n",
    "# in_plane = (points@R.T)[:,:,1:] #-np.array([1]+[0]*(c-1))/np.sqrt(c)\n",
    "\n",
    "# # Animate points of in_plane as moving scatter plot\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# scat = ax.scatter(in_plane[0,:,0], in_plane[0,:,1],s=30)\n",
    "\n",
    "# ax.set_xlim([-0.8,0.8])\n",
    "# ax.set_ylim([-0.9,0.6])\n",
    "\n",
    "# def update(frame_number):\n",
    "#     scat.set_offsets(in_plane[frame_number])\n",
    "\n",
    "# ani = animation.FuncAnimation(fig, update, frames=n_steps, interval=50)\n",
    "# ani.save('test.gif', writer='imagemagick', fps=30)\n",
    "# plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import comb as binom\n",
    "\n",
    "def chromatic_polynomial(x,n,m,g,k):\n",
    "    out = 0\n",
    "    for i in range(n+1):\n",
    "        if i<g-1:\n",
    "            out += (-x)**i*binom(m,i)\n",
    "        else:\n",
    "            out += (-x)**i*(binom(m,g-1)-k)\n",
    "    return out\n",
    "\n",
    "def chromatic_polynomial2(x,n,m,g,k):\n",
    "    out = 0\n",
    "    for i in range(g):\n",
    "        if i<g-1:\n",
    "            out += (x**(n-i))*(-1)**i*binom(m,i)\n",
    "    out += x^(n-g+1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[(0, 0, 0, 0), (0, 0, 0, 1), (0, 0, 0, 2), (0, 0, 0, 3), (0, 0, 1, 0), (0, 0, 1, 1), (0, 0, 1, 2), (0, 0, 1, 3), (0, 0, 2, 0), (0, 0, 2, 1), (0, 0, 2, 2), (0, 0, 2, 3), (0, 0, 3, 0), (0, 0, 3, 1), (0, 0, 3, 2), (0, 0, 3, 3), (0, 1, 0, 0), (0, 1, 0, 1), (0, 1, 0, 2), (0, 1, 0, 3), (0, 1, 1, 0), (0, 1, 1, 1), (0, 1, 1, 2), (0, 1, 1, 3), (0, 1, 2, 0), (0, 1, 2, 1), (0, 1, 2, 2), (0, 1, 2, 3), (0, 1, 3, 0), (0, 1, 3, 1), (0, 1, 3, 2), (0, 1, 3, 3), (0, 2, 0, 0), (0, 2, 0, 1), (0, 2, 0, 2), (0, 2, 0, 3), (0, 2, 1, 0), (0, 2, 1, 1), (0, 2, 1, 2), (0, 2, 1, 3), (0, 2, 2, 0), (0, 2, 2, 1), (0, 2, 2, 2), (0, 2, 2, 3), (0, 2, 3, 0), (0, 2, 3, 1), (0, 2, 3, 2), (0, 2, 3, 3), (0, 3, 0, 0), (0, 3, 0, 1), (0, 3, 0, 2), (0, 3, 0, 3), (0, 3, 1, 0), (0, 3, 1, 1), (0, 3, 1, 2), (0, 3, 1, 3), (0, 3, 2, 0), (0, 3, 2, 1), (0, 3, 2, 2), (0, 3, 2, 3), (0, 3, 3, 0), (0, 3, 3, 1), (0, 3, 3, 2), (0, 3, 3, 3), (1, 0, 0, 0), (1, 0, 0, 1), (1, 0, 0, 2), (1, 0, 0, 3), (1, 0, 1, 0), (1, 0, 1, 1), (1, 0, 1, 2), (1, 0, 1, 3), (1, 0, 2, 0), (1, 0, 2, 1), (1, 0, 2, 2), (1, 0, 2, 3), (1, 0, 3, 0), (1, 0, 3, 1), (1, 0, 3, 2), (1, 0, 3, 3), (1, 1, 0, 0), (1, 1, 0, 1), (1, 1, 0, 2), (1, 1, 0, 3), (1, 1, 1, 0), (1, 1, 1, 1), (1, 1, 1, 2), (1, 1, 1, 3), (1, 1, 2, 0), (1, 1, 2, 1), (1, 1, 2, 2), (1, 1, 2, 3), (1, 1, 3, 0), (1, 1, 3, 1), (1, 1, 3, 2), (1, 1, 3, 3), (1, 2, 0, 0), (1, 2, 0, 1), (1, 2, 0, 2), (1, 2, 0, 3), (1, 2, 1, 0), (1, 2, 1, 1), (1, 2, 1, 2), (1, 2, 1, 3), (1, 2, 2, 0), (1, 2, 2, 1), (1, 2, 2, 2), (1, 2, 2, 3), (1, 2, 3, 0), (1, 2, 3, 1), (1, 2, 3, 2), (1, 2, 3, 3), (1, 3, 0, 0), (1, 3, 0, 1), (1, 3, 0, 2), (1, 3, 0, 3), (1, 3, 1, 0), (1, 3, 1, 1), (1, 3, 1, 2), (1, 3, 1, 3), (1, 3, 2, 0), (1, 3, 2, 1), (1, 3, 2, 2), (1, 3, 2, 3), (1, 3, 3, 0), (1, 3, 3, 1), (1, 3, 3, 2), (1, 3, 3, 3), (2, 0, 0, 0), (2, 0, 0, 1), (2, 0, 0, 2), (2, 0, 0, 3), (2, 0, 1, 0), (2, 0, 1, 1), (2, 0, 1, 2), (2, 0, 1, 3), (2, 0, 2, 0), (2, 0, 2, 1), (2, 0, 2, 2), (2, 0, 2, 3), (2, 0, 3, 0), (2, 0, 3, 1), (2, 0, 3, 2), (2, 0, 3, 3), (2, 1, 0, 0), (2, 1, 0, 1), (2, 1, 0, 2), (2, 1, 0, 3), (2, 1, 1, 0), (2, 1, 1, 1), (2, 1, 1, 2), (2, 1, 1, 3), (2, 1, 2, 0), (2, 1, 2, 1), (2, 1, 2, 2), (2, 1, 2, 3), (2, 1, 3, 0), (2, 1, 3, 1), (2, 1, 3, 2), (2, 1, 3, 3), (2, 2, 0, 0), (2, 2, 0, 1), (2, 2, 0, 2), (2, 2, 0, 3), (2, 2, 1, 0), (2, 2, 1, 1), (2, 2, 1, 2), (2, 2, 1, 3), (2, 2, 2, 0), (2, 2, 2, 1), (2, 2, 2, 2), (2, 2, 2, 3), (2, 2, 3, 0), (2, 2, 3, 1), (2, 2, 3, 2), (2, 2, 3, 3), (2, 3, 0, 0), (2, 3, 0, 1), (2, 3, 0, 2), (2, 3, 0, 3), (2, 3, 1, 0), (2, 3, 1, 1), (2, 3, 1, 2), (2, 3, 1, 3), (2, 3, 2, 0), (2, 3, 2, 1), (2, 3, 2, 2), (2, 3, 2, 3), (2, 3, 3, 0), (2, 3, 3, 1), (2, 3, 3, 2), (2, 3, 3, 3), (3, 0, 0, 0), (3, 0, 0, 1), (3, 0, 0, 2), (3, 0, 0, 3), (3, 0, 1, 0), (3, 0, 1, 1), (3, 0, 1, 2), (3, 0, 1, 3), (3, 0, 2, 0), (3, 0, 2, 1), (3, 0, 2, 2), (3, 0, 2, 3), (3, 0, 3, 0), (3, 0, 3, 1), (3, 0, 3, 2), (3, 0, 3, 3), (3, 1, 0, 0), (3, 1, 0, 1), (3, 1, 0, 2), (3, 1, 0, 3), (3, 1, 1, 0), (3, 1, 1, 1), (3, 1, 1, 2), (3, 1, 1, 3), (3, 1, 2, 0), (3, 1, 2, 1), (3, 1, 2, 2), (3, 1, 2, 3), (3, 1, 3, 0), (3, 1, 3, 1), (3, 1, 3, 2), (3, 1, 3, 3), (3, 2, 0, 0), (3, 2, 0, 1), (3, 2, 0, 2), (3, 2, 0, 3), (3, 2, 1, 0), (3, 2, 1, 1), (3, 2, 1, 2), (3, 2, 1, 3), (3, 2, 2, 0), (3, 2, 2, 1), (3, 2, 2, 2), (3, 2, 2, 3), (3, 2, 3, 0), (3, 2, 3, 1), (3, 2, 3, 2), (3, 2, 3, 3), (3, 3, 0, 0), (3, 3, 0, 1), (3, 3, 0, 2), (3, 3, 0, 3), (3, 3, 1, 0), (3, 3, 1, 1), (3, 3, 1, 2), (3, 3, 1, 3), (3, 3, 2, 0), (3, 3, 2, 1), (3, 3, 2, 2), (3, 3, 2, 3), (3, 3, 3, 0), (3, 3, 3, 1), (3, 3, 3, 2), (3, 3, 3, 3)]\n",
      "[1, x + y, x*y, x**2 + y**2, x**2*y + x*y**2, x**2*y**2, x**3 + y**3, x**3*y + x*y**3, x**3*y**2 + x**2*y**3, x**3*y**3]\n"
     ]
    }
   ],
   "source": [
    "import sympy as sp\n",
    "import itertools\n",
    "v=4\n",
    "vals = []\n",
    "for i in range(v):\n",
    "    for j in range(i):\n",
    "        z = i^2+j^2 + i*j \n",
    "        z = z%v\n",
    "        vals.append(z)\n",
    "print(len(set(vals)))\n",
    "\n",
    "# Write a program that enumerates all symmetric polynomials in 2 variables of degree at most 3.\n",
    "x, y = sp.symbols('x y')\n",
    "polynomials = []\n",
    "\n",
    "# simple_polynomials = [x**i * y**j + x**j * y**i for i in range(4) for j in range(i+1)]\n",
    "# Get elementary symmetric polynomials in x and y\n",
    "max_degree = 3\n",
    "simple_polynomials = []\n",
    "for i in range(max_degree+1):\n",
    "    for j in range(i + 1):\n",
    "        if i == j:\n",
    "            simple_polynomials.append(x**i * y**j)\n",
    "        else:\n",
    "            simple_polynomials.append(x**i * y**j + x**j * y**i)\n",
    "\n",
    "# Get elementary symmetric polynomials in x and y\n",
    "n = len(simple_polynomials)\n",
    "# Enumerate all n-tuples of numbers from 0 to v-1\n",
    "# Enumerate all n-tuples of numbers from 0 to v-1\n",
    "n_tuples = list(itertools.product(range(v), repeat=4))\n",
    "print(n_tuples)\n",
    "\n",
    "print(simple_polynomials)\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
